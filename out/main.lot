\babel@toc {english}{}\relax 
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {table}{\numberline {1}{\ignorespaces Example wordmaps for $target = \texttt {verstehen}$}}{8}{table.3.1}%
\contentsline {table}{\numberline {2}{\ignorespaces ID references assigned to full model names}}{11}{table.3.2}%
\contentsline {table}{\numberline {3}{\ignorespaces List of all used models and their hyperparameters. LR = learning rate, WU = warmup steps.}}{12}{table.3.3}%
\addvspace {10\p@ }
\contentsline {table}{\numberline {4}{\ignorespaces Metrics for masked language model trained on the Oscar dataset with Wordmap infused tokenization. Evaluated on sequence classification task.}}{13}{table.4.4}%
\contentsline {table}{\numberline {5}{\ignorespaces Metrics for masked language model trained on the GerParCor dataset with Wordmap infused tokenization. Evaluated on sequence classification task.}}{14}{table.4.5}%
\contentsline {table}{\numberline {6}{\ignorespaces Metrics for masked language model trained on the GerParCor dataset with \ac {bbgc} tokenization. Evaluated on sequence classification task.}}{14}{table.4.6}%
\contentsline {table}{\numberline {7}{\ignorespaces Metrics for masked language model trained on the GerParCor dataset with \ac {bbgc} tokenization. Evaluated on sequence classification task.}}{14}{table.4.7}%
\contentsline {table}{\numberline {8}{\ignorespaces Metrics for masked language model baseline bert-base-german-cased\let \reserved@d =[\def \par }}{14}{table.4.8}%
\contentsline {table}{\numberline {9}{\ignorespaces Test score summary for all evaluated models.}}{14}{table.4.9}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\providecommand \tocbasic@end@toc@file {}\tocbasic@end@toc@file 
